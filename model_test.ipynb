{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kSNLIRrvTbLy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xarray as xr\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "%run \"./topo_physics.ipynb\"\n",
    "%run \"./utils.ipynb\"\n",
    "%run \"./problems.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6FseyEAZmUVb"
   },
   "outputs": [],
   "source": [
    "def get_model(block_size, num_of_layers_1, num_of_layers_2, case_name):\n",
    "  '''读取储存的训练好的模型'''\n",
    "  cnn_model = load_model(\"Model/\"+case_name+\"/Models/cnn_{layers_1}+{layers_2}layers_{Nb}xblock.h5\".format(layers_1=num_of_layers_1,layers_2=num_of_layers_2, Nb=block_size))\n",
    "  fnn_model = load_model(\"Model/\"+case_name+\"/Models/fnn_{layers_1}+{layers_2}layers_{Nb}xblock.h5\".format(layers_1=num_of_layers_1,layers_2=num_of_layers_2, Nb=block_size))\n",
    "  return cnn_model, fnn_model\n",
    "\n",
    "def record_time_topo_simp(x=None, args=None):\n",
    "  '''SIMP方法计时版'''\n",
    "  # Root function that runs the full optimization routine\n",
    "  if args is None:\n",
    "    args = default_args()\n",
    "  if x is None:\n",
    "    x = np.ones((args['nely'], args['nelx'])) * args['volfrac']  # init mass\n",
    "  total_start_time = time.time()\n",
    "  frames = [x.copy()]\n",
    "  ke = get_stiffness_matrix(args['young'], args['poisson'])  # stiffness matrix\n",
    "  total_fem_cost = 0 \n",
    "  losses, sens = [], []\n",
    "  for step in range(args['opt_steps']):\n",
    "    c, x, dc, fem_cost = record_time_optimality_criteria_step(x, ke, args)\n",
    "    total_fem_cost += fem_cost\n",
    "    losses.append(c)\n",
    "    sens.append(dc)\n",
    "    frames.append(x.copy())\n",
    "  total_end_time = time.time()\n",
    "  total_topo_cost = total_end_time - total_start_time\n",
    "  return total_topo_cost, total_fem_cost \n",
    "\n",
    "def record_time_optimality_criteria_step(x, ke, args, penal=3, e_min=1e-9, e_0=1):\n",
    "  fem_start_time = time.time()\n",
    "  c, dc = autograd.value_and_grad(objective)(x, ke, args)\n",
    "  fem_end_time = time.time()\n",
    "  dv = autograd.grad(mean_density)(x, args)\n",
    "  x = optimality_criteria_combine(x, dc, dv, args)\n",
    "  fem_cost = fem_end_time - fem_start_time\n",
    "  return c, x, dc, fem_cost\n",
    "\n",
    "\n",
    "def run_topo_nn(args, problem, cnn_model, fnn_model, block_size, reduced_problem=None, verbose=False):\n",
    "  '''嵌入神经网络的拓扑优化主函数（计时版）'''\n",
    "  # Root function that runs the full optimization routine\n",
    "  total_start_time = time.time()\n",
    "  x = np.ones((args['nely'], args['nelx'])) * args['volfrac']  # init mass\n",
    "  frames = [x.copy()]\n",
    "  ke = get_stiffness_matrix(args['young'], args['poisson'])  # stiffness matrix\n",
    "  if not reduced_problem:\n",
    "    reduced_problem = scale_reduction_square(problem, factor=block_size)\n",
    "  sens = []\n",
    "  total_fem_time, total_nn_time = 0, 0\n",
    "  for step in range(args['opt_steps']):\n",
    "    x, dc, fem_time, nn_time = optimality_criteria_step_nn(x, args, reduced_problem, cnn_model, fnn_model, block_size)\n",
    "    sens.append(dc)\n",
    "    frames.append(x.copy())\n",
    "    total_fem_time += fem_time\n",
    "    total_nn_time += nn_time\n",
    "  total_end_time = time.time()\n",
    "  total_topo_time = total_end_time - total_start_time\n",
    "  return frames, sens, total_topo_time, total_fem_time, total_nn_time\n",
    "\n",
    "def optimality_criteria_step_nn(x, args, reduced_problem, cnn_model, fnn_model, block_size):\n",
    "  fem_start_time = time.time()\n",
    "  x_phys = physical_density(x, args, apply_cone_filter=True)\n",
    "  # calculate reduced_u & reduced_sens and reshape them.\n",
    "  x_phys_reduced = average_downsample(x_phys, factor=block_size)\n",
    "  u, reduced_sens = fem_solver(x_phys_reduced, specified_task(reduced_problem))\n",
    "  u = standardize(u)\n",
    "  fem_end_time = time.time()\n",
    "  ux, uy = separate_u(u, args['nelx']//block_size, args['nely']//block_size)\n",
    "  ux_block = coarse_disp_to_block(ux)\n",
    "  uy_block = coarse_disp_to_block(uy)\n",
    "  disp_inputs = np.stack((ux_block, uy_block), axis=-1).reshape(-1,8)\n",
    "  # calculate feature maps\n",
    "  feature_maps = cnn_model(x_phys[None,:]).numpy() #(1,nely,nelx,n_filters)\n",
    "  feature_blocks = features_to_block(feature_maps, block_size) #(num_of_blocks, block_size,block_size,n_filters)\n",
    "  feature_inputs = feature_blocks.reshape(feature_blocks.shape[0],-1) #(num_of_blocks,16/36/64)\n",
    "  fnn_inputs = [feature_inputs, disp_inputs]\n",
    "  fnn_outputs = fnn_model(fnn_inputs).numpy() # (num_of_blocks, 4/9/16)\n",
    "  sens_ratio = block_to_full(fnn_outputs, block_size, args['nely'], args['nelx']) #(nely, nelx)\n",
    "  dc_phyx = ratio_to_value(sens_ratio, reduced_sens)\n",
    "  dc = cone_filter(dc_phyx, args['filter_width'], args['mask'], transpose=True)\n",
    "  nn_end_time = time.time()\n",
    "  dv = autograd.grad(mean_density)(x, args)\n",
    "  x = optimality_criteria_combine(x, dc, dv, args)\n",
    "  fem_time = fem_end_time - fem_start_time\n",
    "  nn_time = nn_end_time - fem_end_time\n",
    "  return x, dc, fem_time, nn_time\n",
    "\n",
    "def features_to_block(features, block_size):\n",
    "  ''' (batch_size, nely, nelx, fillter_size)  into \n",
    "  (batch_size*(nely//block_size)*(nelx//blocksize), block_size, block_size)) blocks'''\n",
    "  nely, nelx, n_filters = features.shape[1], features.shape[2], features.shape[3]\n",
    "  num_of_slice = nelx//block_size\n",
    "  transformed = np.moveaxis(tf.reshape(features,(-1,block_size,num_of_slice,block_size,n_filters)),1,2)\n",
    "  return transformed.reshape(-1,block_size,block_size,n_filters)\n",
    "\n",
    "from skimage.util import view_as_windows\n",
    "def coarse_disp_to_block(image):\n",
    "  '''rolling window with shape (2,2) and stride (1,1)'''\n",
    "  return np.array(view_as_windows(image, window_shape=(2,2), step=(1,1))).reshape(-1,2,2)\n",
    "\n",
    "def block_to_full(blocks, block_size, nely, nelx):\n",
    "  '''(num_of_blocks, block_size**2) into (nely, nelx)'''\n",
    "  num_of_blocks = blocks.shape[0]\n",
    "  num_of_slice_x, num_of_slice_y = nelx//block_size, nely//block_size\n",
    "  blocks = tf.reshape(blocks, (num_of_slice_y, num_of_slice_x, block_size, block_size))\n",
    "  return tf.reshape(tf.experimental.numpy.moveaxis(blocks,1,2),(nely, nelx))\n",
    "\n",
    "from skimage.transform import resize\n",
    "def ratio_to_value(sens_ratio, sens_red):\n",
    "  nely, nelx = sens_ratio.shape[0], sens_ratio.shape[1]\n",
    "  sens_red_expanded = resize(sens_red, (nely,nelx), order=0, preserve_range=True)\n",
    "  return sens_ratio * sens_red_expanded"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3cd6af004486e18d8cd1b1dc71eb6e14b35da0a003c4531af785de1b844902cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
