{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./model_training.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取example_data.ipynb中生成的数据\n",
    "ds_block = xr.open_dataset(\n",
    "   \"Data/block.nc\")\n",
    "ds_full = xr.open_dataset(\n",
    "   \"Data/full.nc\")\n",
    "# 将生成的数据转化为用于神经网络训练的数据集格式\n",
    "BLOCK_SIZE, BATCH_SIZE = 2, 16\n",
    "dens_full, disp_slice, outputs = extract_data(ds_full, ds_block)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({\"dens_input\": dens_full, \"disp_input\": disp_slice}, outputs))\n",
    "train_dataset, _, test_dataset = get_dataset(dataset, dens_full.shape[0], batch_size=BATCH_SIZE)\n",
    "\n",
    "# 初始化神经网络模型\n",
    "num_of_layers_cnn, num_of_layers_fnn = 10, 10\n",
    "cnn = cnn_model(num_of_layers=num_of_layers_cnn)\n",
    "fnn = fnn_model(block_size=BLOCK_SIZE, num_of_layers=num_of_layers_fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.11942468583583832 val_loss: 0.27034232020378113\n",
      "epoch: 1 loss: 0.08815663307905197 val_loss: 0.09534742683172226\n",
      "epoch: 2 loss: 0.0743429884314537 val_loss: 0.08027273416519165\n",
      "epoch: 3 loss: 0.07088963687419891 val_loss: 0.07251618802547455\n",
      "epoch: 4 loss: 0.06744831800460815 val_loss: 0.06912465393543243\n",
      "epoch: 5 loss: 0.06615634262561798 val_loss: 0.06873439997434616\n",
      "epoch: 6 loss: 0.0641382560133934 val_loss: 0.06487612426280975\n",
      "epoch: 7 loss: 0.06272776424884796 val_loss: 0.06317955255508423\n",
      "epoch: 8 loss: 0.06208276376128197 val_loss: 0.06285544484853745\n",
      "epoch: 9 loss: 0.06090536713600159 val_loss: 0.059941988438367844\n",
      "epoch: 10 loss: 0.05962803214788437 val_loss: 0.058155518025159836\n",
      "epoch: 11 loss: 0.05871041119098663 val_loss: 0.056936606764793396\n",
      "epoch: 12 loss: 0.05805955454707146 val_loss: 0.05760783329606056\n",
      "epoch: 13 loss: 0.057444337755441666 val_loss: 0.05832236260175705\n",
      "epoch: 14 loss: 0.056453555822372437 val_loss: 0.05583152920007706\n",
      "epoch: 15 loss: 0.0556657649576664 val_loss: 0.05556557700037956\n",
      "epoch: 16 loss: 0.0555492639541626 val_loss: 0.05413905158638954\n",
      "epoch: 17 loss: 0.054254110902547836 val_loss: 0.05519644170999527\n",
      "epoch: 18 loss: 0.054109346121549606 val_loss: 0.05325564369559288\n",
      "epoch: 19 loss: 0.0535648837685585 val_loss: 0.05533218756318092\n",
      "epoch: 20 loss: 0.052540913224220276 val_loss: 0.05240597203373909\n",
      "epoch: 21 loss: 0.05201305076479912 val_loss: 0.05013979598879814\n",
      "epoch: 22 loss: 0.05230599269270897 val_loss: 0.05237974971532822\n",
      "epoch: 23 loss: 0.050715312361717224 val_loss: 0.050429657101631165\n",
      "epoch: 24 loss: 0.0506788045167923 val_loss: 0.051461730152368546\n",
      "epoch: 25 loss: 0.05092743784189224 val_loss: 0.05059526115655899\n",
      "epoch: 26 loss: 0.04976379871368408 val_loss: 0.05020541697740555\n",
      "epoch: 27 loss: 0.049930278211832047 val_loss: 0.04760172963142395\n",
      "epoch: 28 loss: 0.04880135506391525 val_loss: 0.049416761845350266\n",
      "epoch: 29 loss: 0.048835624009370804 val_loss: 0.0468352809548378\n",
      "epoch: 30 loss: 0.04800838977098465 val_loss: 0.04643535986542702\n",
      "epoch: 31 loss: 0.048798635601997375 val_loss: 0.048876188695430756\n",
      "epoch: 32 loss: 0.04883222281932831 val_loss: 0.04790268838405609\n",
      "epoch: 33 loss: 0.04779820516705513 val_loss: 0.05118247866630554\n",
      "epoch: 34 loss: 0.04772370681166649 val_loss: 0.04603705555200577\n",
      "epoch: 35 loss: 0.04696029797196388 val_loss: 0.04516415670514107\n",
      "epoch: 36 loss: 0.046335574239492416 val_loss: 0.046462878584861755\n",
      "epoch: 37 loss: 0.04640420898795128 val_loss: 0.046590909361839294\n",
      "epoch: 38 loss: 0.045584537088871 val_loss: 0.04589470475912094\n",
      "epoch: 39 loss: 0.045215312391519547 val_loss: 0.04522380977869034\n",
      "epoch: 40 loss: 0.04586591571569443 val_loss: 0.04567775875329971\n",
      "epoch: 41 loss: 0.045176491141319275 val_loss: 0.04711156710982323\n",
      "epoch: 42 loss: 0.04404693469405174 val_loss: 0.0459371954202652\n",
      "epoch: 43 loss: 0.044969119131565094 val_loss: 0.04425598680973053\n",
      "epoch: 44 loss: 0.04388788715004921 val_loss: 0.043697237968444824\n",
      "epoch: 45 loss: 0.04366515204310417 val_loss: 0.042486123740673065\n",
      "epoch: 46 loss: 0.04342490807175636 val_loss: 0.0434248149394989\n",
      "epoch: 47 loss: 0.04386196658015251 val_loss: 0.04250320792198181\n",
      "epoch: 48 loss: 0.04307887703180313 val_loss: 0.04324942082166672\n",
      "epoch: 49 loss: 0.04285368323326111 val_loss: 0.042247433215379715\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "best performance: tf.Tensor(0.042247433, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 训练神经网络并保存至\"Model/{casename}\"文件夹下\n",
    "SAVE_MODEL = True\n",
    "test_losses, val_losses = custom_train(block_size=BLOCK_SIZE,cnn_model=cnn,fnn_model=fnn,\\\n",
    "                        loss_function=tf.keras.losses.MeanAbsoluteError(),\\\n",
    "                        num_epoch=50,optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\\n",
    "                        batched_train=train_dataset, batched_test=test_dataset, \n",
    "                        num_of_layers_1=num_of_layers_cnn, num_of_layers_2=num_of_layers_fnn,\n",
    "                        save_model=SAVE_MODEL, \n",
    "                        casename='example')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
